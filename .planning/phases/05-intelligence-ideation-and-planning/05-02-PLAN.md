---
phase: 05-intelligence-ideation-and-planning
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/intelligence/types.ts
  - src/intelligence/sources/hackernews.ts
  - src/intelligence/sources/reddit.ts
  - src/intelligence/sources/producthunt.ts
  - src/intelligence/sources/google-trends.ts
  - src/intelligence/sources/rss.ts
  - src/intelligence/sources/x-trending.ts
  - src/intelligence/scoring.ts
  - src/intelligence/collector.ts
  - src/intelligence/search/perplexity.ts
  - src/intelligence/search/exa.ts
  - src/intelligence/search/tavily.ts
  - src/intelligence/search/brave-search.ts
  - src/intelligence/search/index.ts
  - src/intelligence/competitive.ts
autonomous: true
requirements:
  - INTEL-01
  - INTEL-02
  - INTEL-03
  - INTEL-04
  - INTEL-05
  - INTEL-06

must_haves:
  truths:
    - "Trend sources can be collected from HN, Reddit, Product Hunt, Google Trends RSS, and custom RSS feeds"
    - "Each source gracefully skips when its API key is missing (BYOK degradation)"
    - "Trends are scored by relevance to user's content pillars using keyword matching"
    - "High-scoring trends (70+) get 2-3 suggested angle stubs for content creation"
    - "On-demand search can query Perplexity, Exa, Tavily, and Brave Search"
    - "Competitive intelligence can fetch recent posts from monitored accounts"
  artifacts:
    - path: "src/intelligence/types.ts"
      provides: "RawTrend, ScoredTrend, TrendSource, SearchResult types"
    - path: "src/intelligence/collector.ts"
      provides: "collectTrends orchestrator with BYOK graceful degradation"
      exports: ["collectTrends"]
    - path: "src/intelligence/scoring.ts"
      provides: "Pillar relevance scoring and overall score computation"
      exports: ["scorePillarRelevance", "computeOverallScore", "scoreTrends"]
    - path: "src/intelligence/search/index.ts"
      provides: "Unified search aggregator across all providers"
      exports: ["searchAll"]
    - path: "src/intelligence/competitive.ts"
      provides: "Competitor monitoring via X API"
      exports: ["checkCompetitors"]
  key_links:
    - from: "src/intelligence/collector.ts"
      to: "src/intelligence/sources/*.ts"
      via: "import and call each source adapter"
      pattern: "fetch.*TopStories|fetch.*Reddit|fetch.*ProductHunt"
    - from: "src/intelligence/scoring.ts"
      to: "strategy.yaml pillars"
      via: "keyword matching against pillar names"
      pattern: "pillar.*toLowerCase"
    - from: "src/intelligence/search/index.ts"
      to: "src/intelligence/search/*.ts"
      via: "import and call all available search providers"
      pattern: "searchPerplexity|searchExa|searchTavily|searchBrave"
---

<objective>
Build the intelligence collection layer: source adapters for 6 trend sources, pillar relevance scoring, an orchestrator with BYOK graceful degradation, 4 on-demand search clients, and competitor monitoring.

Purpose: This is the data-gathering backbone that feeds into weekly planning and idea generation. Without trend data, planning is just random topic generation.
Output: Complete src/intelligence/ directory with types, source adapters, scoring, collector orchestrator, search clients, and competitive intelligence.
</objective>

<execution_context>
@/home/hybridz/.claude/get-shit-done/workflows/execute-plan.md
@/home/hybridz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/platforms/x/client.ts
@src/content/topic-suggest.ts
@.planning/phases/05-intelligence-ideation-and-planning/05-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create intelligence types, source adapters, and scoring engine</name>
  <files>
    src/intelligence/types.ts
    src/intelligence/sources/hackernews.ts
    src/intelligence/sources/reddit.ts
    src/intelligence/sources/producthunt.ts
    src/intelligence/sources/google-trends.ts
    src/intelligence/sources/rss.ts
    src/intelligence/sources/x-trending.ts
    src/intelligence/scoring.ts
  </files>
  <action>
First, install rss-parser: `bun add rss-parser`

**src/intelligence/types.ts:**
Define core types:
- `RawTrend` interface: { title, url?, source, sourceScore?, publishedAt?, tags? }
- `ScoredTrend` interface: { id (crypto.randomUUID), title, url?, source, sourceScore, pillarRelevance: Record<string, number>, overallScore, suggestedAngles?, detectedAt, expiresAt? }
- `SearchResult` interface: { title, url, snippet, source }
- `TrendSource` type literal: "hackernews" | "reddit" | "producthunt" | "google-trends" | "rss" | "x"
- `SearchProvider` type literal: "perplexity" | "exa" | "tavily" | "brave"
- `Pillar` interface: { name: string; weight: number }

**Source adapters** (each exports a single async function returning RawTrend[]):

1. **hackernews.ts** - `fetchHNTopStories(limit = 30)`: Fetch topstories IDs from `https://hacker-news.firebaseio.com/v0/topstories.json`, then fetch each item. Filter type === 'story'. No auth needed.

2. **reddit.ts** - `fetchRedditTrending(subreddits: string[], limit = 10)`: Requires REDDIT_CLIENT_ID + REDDIT_CLIENT_SECRET env vars. Get OAuth app-only token from `https://www.reddit.com/api/v1/access_token` (grant_type=client_credentials). Then fetch `https://oauth.reddit.com/r/{sub}/hot.json?limit={limit}` for each subreddit. Map to RawTrend with score as sourceScore.

3. **producthunt.ts** - `fetchProductHuntFeatured(limit = 10)`: Requires PRODUCTHUNT_TOKEN env var. GraphQL query to `https://api.producthunt.com/v2/api/graphql` with Bearer token. Query `posts(first: $limit, order: RANKING)` for today's featured products. Map name + tagline to title.

4. **google-trends.ts** - `fetchGoogleTrends()`: Parse RSS from `https://trends.google.com/trending/rss?geo=US` using rss-parser. No auth needed. Map each item to RawTrend with title and link.

5. **rss.ts** - `fetchRSSFeeds(feedUrls: string[], limit = 5)`: Parse each URL with rss-parser. Gracefully skip feeds that fail. Return latest N items per feed as RawTrend.

6. **x-trending.ts** - `fetchXTrending(xClient)`: Use existing XClient to get user's home timeline (recent posts from followed accounts). Requires XClient instance. Map tweets to RawTrend with like_count as sourceScore.

**src/intelligence/scoring.ts:**
- `scorePillarRelevance(trendTitle: string, pillars: Pillar[])`: Record<string, number> -- keyword matching as shown in RESEARCH.md. Split pillar name into words, check includes on lowercased title. Full phrase match bonus. Cap at 100.
- `computeOverallScore(pillarScores, sourceScore, pillars)`: number -- weighted average of pillar relevance (60%) + normalized source popularity (40%). sourceScore normalization: HN scores map 0-500 to 0-100, Reddit scores map 0-10000 to 0-100.
- `scoreTrends(rawTrends: RawTrend[], pillars: Pillar[])`: ScoredTrend[] -- maps each raw trend through scoring, assigns id, detectedAt, sets expiresAt to 30 days from now.
- `generateAngleStubs(trendTitle: string)`: string[] -- returns 2-3 angle stubs using the ANGLES list pattern from topic-suggest.ts (hot-take, how-to, trend, myth-busting, etc.). Simple template fill: replace {pillar} with trend title.
  </action>
  <verify>Run `bun run check` to confirm all files compile. Verify rss-parser is in package.json. Grep for all 6 source functions to confirm they exist.</verify>
  <done>All 6 source adapters exist and export their fetch functions. Scoring engine scores trends by pillar relevance. Types are defined and exported.</done>
</task>

<task type="auto">
  <name>Task 2: Create collector orchestrator, search clients, and competitive intelligence</name>
  <files>
    src/intelligence/collector.ts
    src/intelligence/search/perplexity.ts
    src/intelligence/search/exa.ts
    src/intelligence/search/tavily.ts
    src/intelligence/search/brave-search.ts
    src/intelligence/search/index.ts
    src/intelligence/competitive.ts
  </files>
  <action>
**src/intelligence/collector.ts** - `collectTrends(pillars: Pillar[])`:
- Orchestrates all source adapters with BYOK graceful degradation pattern
- HN and Google Trends always called (no auth needed)
- Reddit called only if REDDIT_CLIENT_ID is set
- Product Hunt called only if PRODUCTHUNT_TOKEN is set
- RSS feeds called if strategy.yaml has customRssFeeds configured (read from strategy.yaml)
- X trending called only if DATABASE_URL is set (needs XClient with stored token)
- Each source wrapped in try/catch -- log error and continue
- Returns all collected RawTrend[] plus an errors array for logging
- Export: `collectTrends`, `collectBreakingNews` (lighter version: HN top 10 + X trending only, for INTEL-02 poller)

**Search clients** (each exports an async function: `search(query: string): Promise<SearchResult[]>`):
- All use native fetch() -- no SDKs needed
- All check for their env var and return empty array if missing

1. **perplexity.ts** - `searchPerplexity(query)`: POST to `https://api.perplexity.ai/chat/completions` with model "sonar" and the query as user message. Requires PERPLEXITY_API_KEY. Parse the response content as search results.

2. **exa.ts** - `searchExa(query)`: POST to `https://api.exa.ai/search` with query, type "auto", numResults 5. Requires EXA_API_KEY. Map results to SearchResult[].

3. **tavily.ts** - `searchTavily(query)`: POST to `https://api.tavily.com/search` with query, searchDepth "basic", maxResults 5. Requires TAVILY_API_KEY. Map results to SearchResult[].

4. **brave-search.ts** - `searchBrave(query)`: GET to `https://api.search.brave.com/res/v1/web/search?q={query}&count=5` with X-Subscription-Token header. Requires BRAVE_API_KEY. Map web.results to SearchResult[].

**src/intelligence/search/index.ts** - unified search aggregator:
- Export `searchAll(query: string): Promise<SearchResult[]>` that calls all available providers (check env vars) and merges results into a single deduplicated array.
- Each provider called in parallel via Promise.allSettled -- failures logged but don't block others.
- Deduplicate by URL.

**src/intelligence/competitive.ts** - `checkCompetitors(db, userId)`:
- Query monitoredAccounts table for user's tracked accounts
- For X platform accounts, use XClient to fetch recent tweets via user lookup
- Compare posting frequency and topics with user's content pillars
- Return structured report: { account, recentTopics: string[], postFrequency: number, gapSuggestions: string[] }
- If no monitored accounts or no X token, return empty array
  </action>
  <verify>Run `bun run check` to confirm all files compile. Grep for collectTrends, searchAll, searchPerplexity, searchExa, searchTavily, searchBrave, checkCompetitors exports.</verify>
  <done>Collector orchestrator aggregates all sources with BYOK degradation. Four search clients exist with unified searchAll aggregator. Competitive intelligence module queries monitored accounts. All gracefully handle missing credentials.</done>
</task>

</tasks>

<verification>
- `bun run check` passes
- `rss-parser` in package.json dependencies
- src/intelligence/ directory has types.ts, collector.ts, scoring.ts, competitive.ts
- src/intelligence/sources/ has all 6 source files
- src/intelligence/search/ has all 4 search client files plus index.ts
- Each source adapter exports a named function
- Collector returns RawTrend[] and handles missing API keys gracefully
- searchAll merges results from all available providers
</verification>

<success_criteria>
Complete intelligence collection layer that can gather trends from 6 sources, score them by pillar relevance, search 4 providers on demand via unified searchAll, and monitor competitors. All BYOK sources degrade gracefully when keys are missing.
</success_criteria>

<output>
After completion, create `.planning/phases/05-intelligence-ideation-and-planning/05-02-SUMMARY.md`
</output>
