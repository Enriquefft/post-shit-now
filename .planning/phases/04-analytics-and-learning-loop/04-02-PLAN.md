---
phase: 04-analytics-and-learning-loop
plan: 02
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - src/trigger/analytics-collector.ts
  - src/analytics/collector.ts
  - src/analytics/fatigue.ts
  - src/analytics/fatigue.test.ts
autonomous: true
requirements: [ANLYT-01, LEARN-08]

must_haves:
  truths:
    - "Analytics collector runs daily as a Trigger.dev scheduled task and fetches X metrics for published posts"
    - "Metrics are fetched with tiered cadence: more frequent for recent posts, less for older"
    - "Thread posts have all tweet IDs fetched and metrics aggregated"
    - "Follower count is tracked on each collection run"
    - "Declining engagement on a topic (3 consecutive lower scores) flags it as fatigued"
    - "Fatigued topics are deprioritized in suggestions but not blocked"
  artifacts:
    - path: "src/trigger/analytics-collector.ts"
      provides: "Trigger.dev scheduled task for daily analytics collection"
      contains: "schedules.task"
    - path: "src/analytics/collector.ts"
      provides: "Core collection logic: fetch metrics, compute scores, upsert, track followers"
      exports: ["collectAnalytics"]
    - path: "src/analytics/fatigue.ts"
      provides: "Topic fatigue detection with declining trend algorithm"
      exports: ["detectTopicFatigue"]
    - path: "src/analytics/fatigue.test.ts"
      provides: "Tests for fatigue detection"
      contains: "detectTopicFatigue"
  key_links:
    - from: "src/trigger/analytics-collector.ts"
      to: "src/analytics/collector.ts"
      via: "import collectAnalytics"
      pattern: "import.*collectAnalytics"
    - from: "src/analytics/collector.ts"
      to: "src/platforms/x/client.ts"
      via: "XClient.getTweets for batch metric fetch"
      pattern: "client\\.getTweets"
    - from: "src/analytics/collector.ts"
      to: "src/analytics/scoring.ts"
      via: "computeEngagementScore and computeEngagementRateBps"
      pattern: "computeEngagement"
    - from: "src/analytics/collector.ts"
      to: "src/core/db/schema.ts"
      via: "postMetrics table for upsert"
      pattern: "postMetrics"
---

<objective>
Build the analytics data pipeline: a Trigger.dev daily cron that fetches X engagement metrics, computes scores, and stores them. Also build content fatigue detection for overused topics.

Purpose: The collector is the input pipeline for the entire learning loop. Without daily metric collection, there is nothing to score, review, or learn from. Fatigue detection prevents topic stagnation.
Output: Working analytics collector task, fatigue detection module with tests.
</objective>

<execution_context>
@/home/hybridz/.claude/get-shit-done/workflows/execute-plan.md
@/home/hybridz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-analytics-and-learning-loop/04-RESEARCH.md
@.planning/phases/04-analytics-and-learning-loop/04-01-SUMMARY.md
@src/trigger/watchdog.ts
@src/trigger/publish-post.ts
@src/core/db/schema.ts
@src/platforms/x/client.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Analytics collector (Trigger.dev task + core logic)</name>
  <files>
    src/analytics/collector.ts
    src/trigger/analytics-collector.ts
  </files>
  <action>
**Core collection logic (src/analytics/collector.ts):**

Create `collectAnalytics` function that:

1. **Query published posts:** Select from `posts` table where status="published", platform="x", publishedAt within last 30 days (X API metric window constraint). Include `platformPostIds` for thread detection.

2. **Tiered collection cadence per research recommendation:** Filter posts by age to decide which to collect on this run:
   - Posts 0-3 days old: always collect (every run)
   - Posts 4-7 days old: collect daily (every run since cron is daily)
   - Posts 8-30 days old: collect only if `collectedAt` is NULL or older than 3 days
   This is checked by left-joining `postMetrics` on postId and filtering by `collectedAt`.

3. **Gather all tweet IDs:** For each post, use `externalPostId` for single tweets, or all IDs from `platformPostIds` for threads. Deduplicate.

4. **Batch fetch metrics:** Use `XClient.getTweets()` (which handles chunking at 100 IDs internally). Pass `tweetFields: ["public_metrics", "non_public_metrics"]`.

5. **Compute and upsert per post:** For each post:
   - If thread: use `aggregateThreadMetrics()` from scoring.ts to combine metrics from all tweets
   - If single: use the tweet metrics directly
   - Call `computeEngagementScore()` and `computeEngagementRateBps()`
   - Upsert into `postMetrics` table (ON CONFLICT on postId+platform, update all metric and score columns, set new collectedAt)
   - Include post context: extract format from post metadata, topic/pillar from post metadata if available

6. **Track follower count:** Call `XClient.getMe({ userFields: ["public_metrics"] })`. Query preferenceModel for this userId. Append `{ count, date }` to `followerHistory` jsonb array. If no preferenceModel row exists, create one with just followerHistory.

7. **Return summary:** `{ postsCollected: number, followerCount: number, apiCallsMade: number }`.

Handle errors per-post (catch, log, continue) — don't let one post failure stop the entire collection. Use the same env loading pattern as watchdog.ts (DATABASE_URL, HUB_ENCRYPTION_KEY, X_CLIENT_ID, X_CLIENT_SECRET). Token refresh follows the same inline pattern as publish-post.ts.

**Trigger.dev task (src/trigger/analytics-collector.ts):**

Follow the exact pattern from watchdog.ts:
```
export const analyticsCollector = schedules.task({
  id: "analytics-collector",
  cron: "0 6 * * *",  // 6am UTC daily
  maxDuration: 300,    // 5 minutes
  run: async (payload) => {
    // Load env, create DB connection, fetch OAuth token, create XClient
    // Call collectAnalytics(db, client, userId)
    // Log summary
  },
});
```

Use `logger` from `@trigger.dev/sdk` for structured logging. Handle missing env vars gracefully (log error and return, don't throw).
  </action>
  <verify>
    Run `npx tsc --noEmit` to confirm types are correct.
    Verify the Trigger.dev task file exports a valid schedules.task.
  </verify>
  <done>
    Analytics collector runs as daily cron via Trigger.dev. Fetches metrics with tiered cadence based on post age. Threads have aggregated metrics. Follower count tracked. Per-post error isolation. All metrics stored in postMetrics table with scores.
  </done>
</task>

<task type="auto">
  <name>Task 2: Content fatigue detection with tests</name>
  <files>
    src/analytics/fatigue.test.ts
    src/analytics/fatigue.ts
  </files>
  <action>
**Tests first (src/analytics/fatigue.test.ts):**

Test `detectTopicFatigue`:
- 3 posts on same topic with declining scores [80, 60, 40] -> fatigued
- 3 posts on same topic with increasing scores [40, 60, 80] -> not fatigued
- 3 posts on same topic, middle dips but last recovers [80, 40, 60] -> not fatigued (must be strictly declining)
- Only 2 posts on topic -> not enough data, skip
- Multiple topics: one fatigued, one healthy -> returns only the fatigued one
- Empty input -> empty result

Test `isTopicFatigued` (helper for checking against preference model):
- Topic in fatigued list with future cooldown date -> true
- Topic in fatigued list with past cooldown date -> false (expired)
- Topic not in list -> false

**Implementation (src/analytics/fatigue.ts):**

```typescript
interface FatigueResult {
  topic: string;
  status: "fatigued";
  lastScores: number[];
  suggestion: string;
}
```

`detectTopicFatigue(posts: Array<{ topic: string; score: number; publishedAt: Date }>)`:
- Group posts by topic
- For each topic with >= 3 posts, sort by publishedAt ascending
- Check last 3: strictly declining (each lower than previous)
- Return FatigueResult[] for declining topics
- The suggestion should recommend alternatives per CONTEXT.md: "Topic X has been cooling -- consider [alternative pillar]" (the alternative is not computed here, just referenced generically)

`isTopicFatigued(topic: string, fatiguedTopics: Array<{ topic: string; cooldownUntil: string }>)`:
- Check if topic exists in list AND cooldownUntil is in the future
- Used by content brain to warn during /psn:post per user decision

`updateFatiguedTopics(currentFatigued, newDetections, cooldownDays = 14)`:
- Merge new detections into existing fatigued list
- Set cooldownUntil = now + cooldownDays
- Remove expired cooldowns
- Return updated list (for writing to preferenceModel.fatiguedTopics)

Export all functions and types.
  </action>
  <verify>
    Run `npx vitest run src/analytics/fatigue.test.ts` — all tests pass.
    Run `npx tsc --noEmit` — no type errors.
  </verify>
  <done>
    Fatigue detection identifies declining engagement trends (3 consecutive lower scores per topic). Cooldown management with expiry. Helper function for checking fatigue status during post generation. All functions tested.
  </done>
</task>

</tasks>

<verification>
- `npx vitest run src/analytics/fatigue.test.ts` passes
- `npx tsc --noEmit` compiles without errors
- analytics-collector.ts exports a valid Trigger.dev schedules.task
- collector.ts handles tiered collection, thread aggregation, follower tracking, per-post error isolation
</verification>

<success_criteria>
- Daily analytics collector Trigger.dev task with tiered collection cadence
- Thread metrics aggregated from all tweet IDs
- Follower count tracked per run
- Content fatigue detection tested and working
- Fatigue cooldown management with expiry
</success_criteria>

<output>
After completion, create `.planning/phases/04-analytics-and-learning-loop/04-02-SUMMARY.md`
</output>
